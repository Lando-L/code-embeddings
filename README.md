# code-embeddings
The ability to generate natural language from source code is an open research topic and has gained an increasing popularity in recent years. Due to the nature of open research topics, there is no silverbullet in solving this problem, meaning there are different promising approaches being explored by the research community.

This specific work is heavily inspired by [Uri Alon](http://urialon.cswp.cs.technion.ac.il), [Shaked Brody](http://www.cs.technion.ac.il/people/shakedbr/), [Omer Levy](https://levyomer.wordpress.com) and [Eran Yahav](http://www.cs.technion.ac.il/~yahave/), "code2seq: Generating Sequences from Structured Representations of Code" [[PDF]](https://openreview.net/pdf?id=H1gKYo09tX) and relies partly on their unofficial implementation on GitHub [[Repository]](https://github.com/Kolkir/code2seq).

## Motivation
Documentation plays an important role in the process of software development. It helps other developers to better understand the software's source code and enables them to build on each others ideas.

The aim of this project is to improve the experience of developers with poorly documented code, when reaching out to the original authors is not an option.

## Quick Start
A good starting point to get an overview of what this project is about, is to go through the quickstart [notebook](https://github.com/Lando-L/code-embeddings/blob/develop/src/quickstart.ipynb).

## Setup
If you want to train and evaluate the model yourself, you can find more information about the project's structure and a training and evaluation guide in the [wiki](https://github.com/Lando-L/code-embeddings/wiki).
